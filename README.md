# Pr√°ctica 4 ‚Äì Visi√≥n por Computador
## Lectura de matr√≠culas de veh√≠culos mediante OCR

Esta pr√°ctica consiste en la **lectura autom√°tica de matr√≠culas de veh√≠culos** utilizando t√©cnicas de **detecci√≥n de objetos (YOLO)** y **reconocimiento √≥ptico de caracteres (OCR)**.

---

## 1. Entrenamiento de yolo

En primer lugar, he empleado un modelo **YOLO** preentrenado para detectar **veh√≠culos y personas**.  
Posteriormente, realic√© un **fine-tuning** sobre el modelo **YOLOv11s** con el objetivo de detectar espec√≠ficamente las **matr√≠culas** presentes en los veh√≠culos detectados.

Para ello:

- Captur√© **260 im√°genes de matr√≠culas** reales.  
- Las **etiquet√© manualmente** utilizando la herramienta **LabelMe**.

El modelo fue entrenado con el siguiente comando:

```bash
yolo detect train data=dataset.yaml model=yolo11s.pt epochs=150 imgsz=640 batch=16 device=0 degrees=10 translate=0.1 scale=0.2 shear=0.05 perspective=0.0 flipud=0.0 fliplr=0.5 mosaic=True mixup=True
```

A continuaci√≥n, se explica brevemente el significado de los principales par√°metros:

- `data=dataset.yaml` ‚Üí archivo de configuraci√≥n con las rutas del dataset.  
- `model=yolo11s.pt` ‚Üí modelo base utilizado para el entrenamiento.  
- `epochs=150` ‚Üí n√∫mero de √©pocas de entrenamiento.  
- `imgsz=640` ‚Üí tama√±o de las im√°genes de entrada.  
- `batch=16` ‚Üí tama√±o del lote de entrenamiento.  
- `device=0` ‚Üí GPU utilizada (en este caso, la primera).  
- `degrees`, `translate`, `scale`, `shear`, `perspective` ‚Üí transformaciones de *data augmentation*.  
- `flipud` / `fliplr` ‚Üí inversi√≥n vertical u horizontal de las im√°genes.  
- `mosaic` / `mixup` ‚Üí t√©cnicas de *data augmentation* para combinar im√°genes y mejorar la robustez del modelo.
---


![Resultado del modelo](./runs/detect/train11/results.png)
---
El entrenamiento muestra una **mejora progresiva y estable** a lo largo de las 150 √©pocas, con una **reducci√≥n constante de las p√©rdidas** (losses) y un **incremento notable en las m√©tricas de precisi√≥n y mAP**.

En las primeras √©pocas, las m√©tricas presentaban mucha variabilidad y valores bajos, pero a partir de la √©poca 30 aproximadamente, el modelo comienza a estabilizarse y mejorar de forma consistente hasta alcanzar un **rendimiento muy bueno a partir de la √©poca 70**.

---
### P√©rdida de Entrenamiento
- **Box Loss (train/box_loss)** pas√≥ de ‚âà2.4 a ‚âà0.61, mostrando una reducci√≥n clara y continua.
- **Cls Loss (train/cls_loss)** disminuy√≥ de ‚âà7.3 a ‚âà0.32, una mejora dr√°stica.
- **Dfl Loss (train/dfl_loss)** baj√≥ de ‚âà2.4 a ‚âà 0.89, mostrando convergencia.

Las p√©rdidas de entrenamiento disminuyen de forma estable, sin indicios de sobreajuste temprano. Esto sugiere que el modelo est√° aprendiendo patrones relevantes de los datos.

### P√©rdida de Validaci√≥n
- Las p√©rdidas de validaci√≥n siguieron un patr√≥n similar al entrenamiento.
- A partir de la √©poca 50, las p√©rdidas se estabilizan con valores bajos y consistentes.

El modelo **generaliza bien** sobre los datos de validaci√≥n, sin un aumento repentino de las p√©rdidas (lo que indicar√≠a overfitting).

---

### M√©tricas de Rendimiento

### üî∏ Precisi√≥n (metrics/precision(B))
- Aument√≥ desde **~0.54** hasta **~0.99**, mostrando una mejora clara.

### üî∏ Recall (metrics/recall(B))
- Subi√≥ de **~0.64** a **~0.98**, lo que indica una gran capacidad del modelo para detectar correctamente los objetos.

### üî∏ mAP50 (metrics/mAP50(B))
- Comenz√≥ en **0.56** y alcanz√≥ **‚âà0.98‚Äì0.99**, un buen rendimiento.

### üî∏ mAP50-95 (metrics/mAP50-95(B))
- Pas√≥ de **~0.22** a **‚âà0.69**, indicando buena capacidad en distintos umbrales de IoU.

Las m√©tricas reflejan un modelo **altamente preciso y robusto**, especialmente en mAP50, que supera el 98 %.  
El mAP50-95 tambi√©n es elevado, se√±al de que el modelo tiene buen rendimiento incluso con criterios m√°s estrictos.

---

### Tasa de Aprendizaje (lr)

- Los valores de `lr/pg0`, `lr/pg1` y `lr/pg2` disminuyen gradualmente de **0.00024** a **~0.0000332**, mostrando una correcta estrategia de reducci√≥n del learning rate.  
- Esta reducci√≥n progresiva contribuye a una convergencia m√°s estable hacia el final del entrenamiento.

---


## 2. Procesamiento de v√≠deos

Una vez entrenado el modelo, se aplic√≥ el detector a **dos v√≠deos grabados para este prop√≥sito**. Adem√°s el ocr utilizado ha sido easyocr puesto que ha sido el que mejor resultados ha dado seg√∫n la comparativa realizada entre este y tesseract, la cual se detallar√° m√°s adelante:

- El primero muestra los **veh√≠culos por la parte delantera**.  
- El segundo, los **veh√≠culos por la parte trasera**.

A continuaci√≥n se incluyen los resultados visuales del modelo en ambos v√≠deos (GIFs):

![](./gifs/gif_matriculas_delante.gif)
![](./gifs/gif_matriculas_detras.gif)

Adem√°s los resultados del procesamiento se volcar√≥n en dos archivos csv "detecciones_video_delante.csv" y "detecciones_video_delante.csv" guardando la siguiente informaci√≥n:

frame,tipo_objeto,confianza,tracking_id,x1,y1,x2,y2,matricula_conf,mx1,my1,mx2,my2,texto_matricula

---

### 3. Preservaci√≥n del anonimato

Para proteger la identidad de las personas presentes en los v√≠deos, utilic√© un modelo YOLO especializado en **detecci√≥n de rostros**, disponible en el siguiente repositorio:  
[Yusepp/YOLOv8-Face](https://github.com/Yusepp/YOLOv8-Face)

Tras detectar las caras, apliqu√© un **efecto de pixelado** sobre ellas para garantizar el anonimato.

---
### 4. Comparativa OCR: EasyOCR vs Tesseract

Para el reconocimiento √≥ptico de caracteres (OCR) en las matr√≠culas, se probaron dos sistemas distintos:

- **EasyOCR**
- **Tesseract OCR**

Con el objetivo de comparar su rendimiento, se seleccionaron **50 im√°genes aleatorias** del conjunto de datos y se evalu√≥ el desempe√±o de ambos modelos.  
Para cada imagen se midi√≥:
- Si el texto completo de la matr√≠cula se reconoc√≠a **exactamente**.
- La **precisi√≥n car√°cter a car√°cter** (*character accuracy*).
- El **tiempo medio de ejecuci√≥n** por imagen.

---

#### 4.1. Resultados de Exactitud Total

![Aciertos exactos por OCR](./resultados/grafico_aciertos.png)

En este gr√°fico se muestran los **porcentajes de aciertos exactos**, es decir, el n√∫mero de matr√≠culas en las que el texto detectado coincidi√≥ completamente con el texto real (*ground truth*).

Los resultados evidencian una **ventaja clara de EasyOCR**, que logr√≥ una mayor proporci√≥n de coincidencias exactas respecto a Tesseract.  
Tesseract cometi√≥ errores frecuentes debido a caracteres adicionales o confusiones comunes (por ejemplo, letras por n√∫meros), mientras que EasyOCR mantuvo un reconocimiento m√°s estable.

---

#### 4.2. Precisi√≥n de Caracteres

![Precisi√≥n](./resultados/grafico_accuracy.png)

La precisi√≥n por caracteres muestra el porcentaje de coincidencias entre los caracteres reconocidos y los reales.  
Aqu√≠ se observa nuevamente que **EasyOCR supera a Tesseract**, alcanzando una **precisi√≥n media m√°s alta**.  
Aunque Tesseract logra reconocer parcialmente algunas matr√≠culas, su rendimiento es inconsistente con placas m√°s degradadas o con iluminaci√≥n variable.

---

#### 4.3. Tiempos de Procesamiento

![TIempo de ejecuci√≥n](./resultados/grafico_tiempo.png)

En t√©rminos de velocidad, **Tesseract fue ligeramente m√°s r√°pido** en promedio.  
Sin embargo, la diferencia temporal entre ambos m√©todos es peque√±a, y EasyOCR sigue siendo suficientemente r√°pido para un flujo de trabajo en tiempo real o semiautom√°tico.

---

### 5. Archivos extras

El dataset y los v√≠deos utilizados en esta pr√°ctica se encuentran alojados en el siguiente enlace debido a su gran tama√±o: [enlace a drive](https://drive.google.com/drive/folders/1QH7XDKuDlbvZdsLUQIi_tHcB7mLjjpVZ?usp=sharing)
